[{
  "history_id" : "3483i33jmxh",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684268295708,
  "history_end_time" : 1684268295708,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "c7sgfoh89u2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684268093742,
  "history_end_time" : 1684268093742,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "xof9prbpf6s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684267389197,
  "history_end_time" : 1684267389197,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "ocia6fel9re",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684266056687,
  "history_end_time" : 1684266056687,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "gaspnlkb1ot",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684265995098,
  "history_end_time" : 1684265995098,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "gb8mk8qfaam",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684265857017,
  "history_end_time" : 1684265857017,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "n2hj8ud74ec",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684265720538,
  "history_end_time" : 1684265720538,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "zkejq284ndg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684265684578,
  "history_end_time" : 1684265684578,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "2plyynqxola",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684264569981,
  "history_end_time" : 1684264569981,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "2tu66red3rm",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684264544452,
  "history_end_time" : 1684264550372,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "0k1f9ea4ic1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684263382634,
  "history_end_time" : 1684263382634,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "cbe4bzn4ms7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684263250322,
  "history_end_time" : 1684263250322,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "25dya67i7nr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684263086332,
  "history_end_time" : 1684263086332,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "l3x9tr9k87n",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684262746506,
  "history_end_time" : 1684262746506,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "izsau85g8i0",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684262105026,
  "history_end_time" : 1684262105026,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "ctl45bv7r6z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684262085472,
  "history_end_time" : 1684262085472,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "9gb8b2vrco2",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1684261824564,
  "history_end_time" : 1684261974110,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "rdlndtw0f9f",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683063256456,
  "history_end_time" : 1683063256456,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "qemk6rj11tg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683063215113,
  "history_end_time" : 1683063215113,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "rb6cs2r89lg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683061007170,
  "history_end_time" : 1683061007170,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "75e1gsuv32s",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683060956368,
  "history_end_time" : 1683060956368,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "rr1xmx4mbzy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683060018648,
  "history_end_time" : 1683060018648,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "26szc8hx4qe",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1683059287079,
  "history_end_time" : 1683059287079,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "j269lef54gz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682444006971,
  "history_end_time" : 1682444006971,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "p3gldnpdi72",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682443926516,
  "history_end_time" : 1682443979654,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "8sdtj792u7h",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682443685802,
  "history_end_time" : 1682443925656,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "atepelecing",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682442641209,
  "history_end_time" : 1682442641209,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "pncjoa8i9lv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682442532360,
  "history_end_time" : 1682442550972,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "3dl6elyt6ut",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682441929628,
  "history_end_time" : 1682441929628,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "vzs7e5mti0z",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682440386657,
  "history_end_time" : 1682440474436,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "5y4pe7cf3mn",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682440235245,
  "history_end_time" : 1682440385657,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "nufej5bspv7",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682440181474,
  "history_end_time" : 1682440234545,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "7f09fqxyebv",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682439988636,
  "history_end_time" : 1682440138045,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "fgdehoiq6gl",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682439640530,
  "history_end_time" : 1682439640530,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "ok44g94w513",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682439488953,
  "history_end_time" : 1682439488953,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "jyvjm4oj2ns",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682439471672,
  "history_end_time" : 1682439471672,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "4f7vgmj5zdw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682437190981,
  "history_end_time" : 1682437217448,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "g6j2x7o87am",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1682434977827,
  "history_end_time" : 1682435038074,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "z48zowq1shr",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681846897181,
  "history_end_time" : 1681846897181,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "mwlfyouardt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681846509209,
  "history_end_time" : 1681846782381,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Stopped"
},{
  "history_id" : "5w5t9knih9c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1681845552440,
  "history_end_time" : 1681845552440,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Skipped"
},{
  "history_id" : "no4e6q5453c",
  "history_input" : "# This file contanis differetnt components to run the model\n# 1. Eddy-Net Object\n# 2. Torch Metrics (metrics to keep track of)\n# 3. Optimizer\n# 4. Loss function\n# 5. Summery writer to write summary\n\nimport torchmetrics\nimport torch\nimport datetime\nimport os\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom data_utils import EddyNet\nfrom convert_to_pytorch_data_loader import *\n\n# 1. Eddy Net\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available():\n    model.to(device=\"cuda\")\n\n\n# 2. Torch Metrics (metrics to keep track of)\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N,task=\"multiclass\"),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n\n\n\n# 3. Optimizer\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\n\n\n# 4. Loss function\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n# 5. Summery writer\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1681842363275,
  "history_end_time" : 1681842365751,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Done"
},{
  "history_id" : "62630xqk3w4",
  "history_input" : "# This file contanis differetnt components to run the model\n# 1. Eddy-Net Object\n# 2. Torch Metrics (metrics to keep track of)\n# 3. Optimizer\n# 4. Loss function\n# 5. Summery writer to write summary\n\nimport torchmetrics\nimport torch\nimport datetime\nimport os\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom data_utils import EddyNet\nfrom convert_to_pytorch_data_loader import *\n\n# 1. Eddy Net\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available():\n    model.to(device=\"cuda\")\n\n\n# 2. Torch Metrics (metrics to keep track of)\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N,task=\"multiclass\"),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n\n\n\n# 3. Optimizer\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\n\n\n# 4. Loss function\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n# 5. Summery writer\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1681841813726,
  "history_end_time" : 1681841816938,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Done"
},{
  "history_id" : "2z8zt7itolr",
  "history_input" : "# This file contanis differetnt components to run the model\n# 1. Eddy-Net Object\n# 2. Torch Metrics (metrics to keep track of)\n# 3. Optimizer\n# 4. Loss function\n# 5. Summery writer to write summary\n\nimport torchmetrics\nimport torch\nimport datetime\nimport os\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom data_utils import EddyNet\nfrom convert_to_pytorch_data_loader import *\n\n# 1. Eddy Net\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available():\n    model.to(device=\"cuda\")\n\n\n# 2. Torch Metrics (metrics to keep track of)\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N,task=\"multiclass\"),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n\n\n\n# 3. Optimizer\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\n\n\n# 4. Loss function\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n# 5. Summery writer\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\n\n\n",
  "history_output" : "Read 24 samples from /home/chetana/ML_eddie/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-1999_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddie/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/2z8zt7itolr/model_components.py\", line 97, in <module>\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\nAttributeError: type object 'datetime.datetime' has no attribute 'datetime'\n",
  "history_begin_time" : 1681841551034,
  "history_end_time" : 1681841558641,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Failed"
},{
  "history_id" : "a9madwpuwhe",
  "history_input" : "# This file contanis differetnt components to run the model\n# 1. Eddy-Net Object\n# 2. Torch Metrics (metrics to keep track of)\n# 3. Optimizer\n# 4. Loss function\n# 5. Summery writer to write summary\n\nimport torchmetrics\nimport torch\nimport datetime\nimport os\n\nfrom torch.utils.tensorboard import SummaryWriter\nfrom data_utils import EddyNet\nfrom convert_to_pytorch_data_loader import *\n\n# 1. Eddy Net\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available():\n    model.to(device=\"cuda\")\n\n\n# 2. Torch Metrics (metrics to keep track of)\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N,task=\"multiclass\"),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n\n\n\n# 3. Optimizer\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\n\n\n# 4. Loss function\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\n# 5. Summery writer\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1681841168919,
  "history_end_time" : 1681841171338,
  "history_notes" : null,
  "history_process" : "n508da",
  "host_id" : "c2lqcn",
  "indicator" : "Done"
},]
