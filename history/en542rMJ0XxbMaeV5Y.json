[{
  "history_id" : "5t6uc2en3vx",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346144,
  "history_end_time" : 1678850346144,
  "history_notes" : null,
  "history_process" : "0ajbp0",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "91atxzpdl7i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346145,
  "history_end_time" : 1678850346145,
  "history_notes" : null,
  "history_process" : "0ps7es",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "xuko6u9x8dy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346145,
  "history_end_time" : 1678850346145,
  "history_notes" : null,
  "history_process" : "ag4g86",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "lq0d8wsjela",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346146,
  "history_end_time" : 1678850346146,
  "history_notes" : null,
  "history_process" : "nzlslh",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "2xfbo0xza2n",
  "history_input" : "# Process data to generate ground truth using py-eddy-tracker\n\nfrom dependency import *\nfrom plot_utils import *\nfrom matplotlib.path import Path\nfrom py_eddy_tracker.poly import create_vertice\n\ndef generate_segmentation_mask_from_file(\n    gridded_ssh_file,\n    date,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=0,\n    y_offset=0,\n):\n    g, g_filtered, anticyclonic, cyclonic = identify_eddies(\n        gridded_ssh_file, date, ssh_var, u_var, v_var, high_pass_wavelength_km\n    )\n    mask = generate_segmentation_mask(\n        g_filtered, anticyclonic, cyclonic, x_offset, y_offset\n    )\n    var = g.grid(ssh_var)\n    var_filtered = g_filtered.grid(ssh_var)\n    return var, var_filtered, mask\n\n\ndef identify_eddies(\n    gridded_ssh_file,\n    date,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n):\n    g = RegularGridDataset(gridded_ssh_file, \"longitude\", \"latitude\")\n    g_filtered = deepcopy(g)  # make a copy so we don't alter the original\n    g_filtered.bessel_high_filter(ssh_var, high_pass_wavelength_km)\n    anticyclonic, cyclonic = g_filtered.eddy_identification(ssh_var, u_var, v_var, date)\n    return g, g_filtered, anticyclonic, cyclonic\n\n\ndef generate_segmentation_mask(\n    grid_dataset, anticyclonic, cyclonic, x_offset, y_offset, plot=False\n):\n    \"\"\"\n    Creates a numpy array to store the segmentation mask for the grid_dataset.\n    The mask contains classes 0: no eddy, 1: anticyclonic eddy, 2: cyclonic eddy.\n    \"\"\"\n    assert (\n        cyclonic.sign_legend == \"Cyclonic\"\n        and anticyclonic.sign_legend == \"Anticyclonic\"\n    ), \"Check whether the correct order for (anti)cyclonic observations were provided.\"\n    mask = np.zeros(grid_dataset.grid(\"adt\").shape, dtype=np.uint8)\n    # cyclonic should have the same: x_name = 'contour_lon_e', y_name = 'contour_lat_e'\n    x_name, y_name = anticyclonic.intern(False)\n    for eddy in anticyclonic:\n        x_list = (eddy[x_name] - x_offset) % 360 + x_offset\n        vertices = create_vertice(x_list, eddy[y_name] + y_offset)\n        i, j = Path(vertices).pixels_in(grid_dataset)\n        mask[i, j] = 1\n\n    for eddy in cyclonic:\n        x_list = (eddy[x_name] - x_offset) % 360 + x_offset\n        y_list = eddy[y_name] + y_offset\n        i, j = Path(create_vertice(x_list, y_list)).pixels_in(grid_dataset)\n        mask[i, j] = 2\n\n    if plot:\n        ax, m,fig = plot_variable(grid_dataset, mask, \"Segmentation Mask\", cmap=\"viridis\")\n    return mask",
  "history_output" : "",
  "history_begin_time" : 1678850346472,
  "history_end_time" : 1678850364728,
  "history_notes" : null,
  "history_process" : "jajowz",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "d6quah750fr",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1678850367949,
  "history_end_time" : 1678850371075,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "is7iyek60u4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346151,
  "history_end_time" : 1678850346151,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "34kbeo3pppk",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346151,
  "history_end_time" : 1678850346151,
  "history_notes" : null,
  "history_process" : "g85teu",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "0de040eecbd",
  "history_input" : "# This generates segmentation efficiently in parallel on a gloabal scale\n\n\nimport logging\n\nfrom generate_ground_truth_parallel_utils import *\nfrom data_loader import *\n\n\nlogging.getLogger(\"pet\").setLevel(logging.ERROR)\n\n# enter the AVISO filename pattern\n# year, month, and day in file_pattern will be filled in get_dates_and_files:\nfile_pattern = \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n# training set: 1998 - 2018\ntrain_dates, train_files = get_dates_and_files(\n    range(1998, 2019), range(1, 2), [10], train_folder, file_pattern\n)\ntrain_adt, train_adt_filtered, train_masks = generate_masks_in_parallel(\n    train_files, train_dates\n)\n\n\n# test set: 2019\ntest_dates, test_files = get_dates_and_files(\n    [2019], range(1, 13), [ 10 ], test_folder, file_pattern\n)\ntest_adt, test_adt_filtered, test_masks = generate_masks_in_parallel(\n    test_files, test_dates\n)",
  "history_output" : "Found 21 files for 1998-2018.\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nSaved masks to /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/global_pet_masks_with_adt_1998-2018.npz\nFound 12 files for 2019.\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nSaved masks to /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/global_pet_masks_with_adt_2019.npz\n",
  "history_begin_time" : 1678850372777,
  "history_end_time" : 1678850550999,
  "history_notes" : null,
  "history_process" : "q20jvx",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "uel4fo5vwa8",
  "history_input" : "# Use the segmask_and_ssh_utils to generate compress file\n\nfrom data_loader import *\nfrom generate_segmentation_in_parallel import *\nfrom segmask_and_ssh_utils import *\n\nlon_range = (-166, -134)\nlat_range = (14, 46)\n\ntrain_subset = subset_arrays(\n    train_masks,\n    train_adt,\n    train_adt_filtered,\n    train_dates,\n    lon_range,\n    lat_range,\n    plot=False,\n    resolution_deg=0.25,\n    save_folder=train_folder,\n)\n\ntest_subset = subset_arrays(\n    test_masks,\n    test_adt,\n    test_adt_filtered,\n    test_dates,\n    lon_range,\n    lat_range,\n    plot=True,\n    resolution_deg=0.25,\n    save_folder=test_folder,\n)",
  "history_output" : "Found 21 files for 1998-2018.\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nSaved masks to /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/global_pet_masks_with_adt_1998-2018.npz\nFound 12 files for 2019.\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nSaved masks to /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/global_pet_masks_with_adt_2019.npz\nSaved mask subset to /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz\nSaved mask subset to /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz\n",
  "history_begin_time" : 1678850551820,
  "history_end_time" : 1678850729972,
  "history_notes" : null,
  "history_process" : "yddm1o",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "tn0qcd5t7k9",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346155,
  "history_end_time" : 1678850346155,
  "history_notes" : null,
  "history_process" : "dhjb5i",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "tcthc48lneq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346155,
  "history_end_time" : 1678850346155,
  "history_notes" : null,
  "history_process" : "zbt6sg",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "1ph4dc0cc8u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346156,
  "history_end_time" : 1678850346156,
  "history_notes" : null,
  "history_process" : "g7a3zf",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "136rckmcryv",
  "history_input" : "from dependency import *\nimport sys\n\nsys.path.insert(0, os.path.dirname(os.getcwd()))\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"   # useful on multi-GPU systems with multiple users\n\n# Fix manual seeds for reproducibility\nimport torch\nseed = 42\ntorch.manual_seed(seed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(seed)\nnp.random.seed(seed)\n\nnum_epochs = 250  # can lower this to save time\nbatch_size = 256",
  "history_output" : "",
  "history_begin_time" : 1678850346977,
  "history_end_time" : 1678850363613,
  "history_notes" : null,
  "history_process" : "mnmaq1",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "1f0wey454p9",
  "history_input" : "from dependency import os\n\ndata_root = os.path.join(os.path.expanduser(\"~\"), \"ML_eddies\")\ntrain_folder = os.path.join(data_root, \"cds_ssh_1998-2018_10day_interval\")\nval_folder = os.path.join(data_root, \"cds_ssh_2019_10day_interval\")\ntrain_file = os.path.join(train_folder, \"subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz\")\nval_file = os.path.join(val_folder, \"subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz\")",
  "history_output" : "Running",
  "history_begin_time" : 1678850731990,
  "history_end_time" : 1678850735099,
  "history_notes" : null,
  "history_process" : "w3hmlz",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "e4at265nu7e",
  "history_input" : "from get_device_config import *\nfrom link_npz_files import *\nfrom torch_data_loader_utils import get_eddy_dataloader\n\n# set binary = false if we want to distinguish between cyclonic and anticyclonic\nbinary = False\nnum_classes = 2 if binary else 3\ntrain_loader, _ = get_eddy_dataloader(train_file, binary=binary, batch_size=batch_size)\nval_loader, _ = get_eddy_dataloader(\n    val_file, binary=binary, batch_size=batch_size, shuffle=False\n)",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n",
  "history_begin_time" : 1678850737004,
  "history_end_time" : 1678850744010,
  "history_notes" : null,
  "history_process" : "28zx21",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "ovzbn7r3wzt",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346161,
  "history_end_time" : 1678850346161,
  "history_notes" : null,
  "history_process" : "d6b94y",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "ofjx2jc5o4g",
  "history_input" : "from convert_to_pytorch_data_loader import *\n\nimport numpy as np\ntrain_masks = train_loader.dataset.masks.copy()\nclass_frequency = np.bincount(train_masks.flatten())\ntotal_pixels = sum(class_frequency)\n\n\nprint(\n    f\"Total number of pixels in training set: {total_pixels/1e6:.2f} megapixels\"\n    f\" across {len(train_masks)} SSH maps\\\\n\"\n    f\"Number of pixels that are not eddies: {class_frequency[0]/1e6:.2f} megapixels \"\n    f\"({class_frequency[0]/total_pixels * 100:.2f}%)\\\\n\"\n    f\"Number of pixels that are anticyclonic eddies: {class_frequency[1]/1e6:.2f} megapixels \"\n    f\"({class_frequency[1]/total_pixels * 100:.2f}%)\\\\n\"\n    f\"Number of pixels that are cyclonic eddies: {class_frequency[2]/1e6:.2f} megapixels \"\n    f\"({class_frequency[2]/total_pixels * 100:.2f}%)\\\\n\"\n)",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\nTotal number of pixels in training set: 0.34 megapixels across 21 SSH maps\nNumber of pixels that are not eddies: 0.26 megapixels (74.53%)\nNumber of pixels that are anticyclonic eddies: 0.05 megapixels (13.34%)\nNumber of pixels that are cyclonic eddies: 0.04 megapixels (12.13%)\n\n",
  "history_begin_time" : 1678850744139,
  "history_end_time" : 1678850750154,
  "history_notes" : null,
  "history_process" : "mh6f0e",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "vadqbzmgffs",
  "history_input" : "import torch\nfrom data_utils import EddyNet\nfrom convert_to_pytorch_data_loader import *\n\nnum_classes = 2 if binary else 3\nmodel_name = \"eddynet\"  # we'll log this in Tensorboard\nmodel = EddyNet(num_classes, num_filters=16, kernel_size=3)\nif torch.cuda.is_available():\n    model.to(device=\"cuda\")",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n",
  "history_begin_time" : 1678850751047,
  "history_end_time" : 1678850757107,
  "history_notes" : null,
  "history_process" : "0w1lsj",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "tlhvb7sppy3",
  "history_input" : "import torch\nfrom convert_to_pytorch_data_loader import *\nfrom create_eddy_net import *\n\ninitial_lr = 1e-6\nmax_lr = 5e-4\n\noptimizer = torch.optim.Adam(model.parameters(), lr=max_lr)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(\n    optimizer,\n    max_lr=max_lr,\n    steps_per_epoch=len(train_loader),\n    epochs=num_epochs,\n    div_factor=max_lr / initial_lr,\n    pct_start=0.3,\n)\n",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n",
  "history_begin_time" : 1678850757184,
  "history_end_time" : 1678850762851,
  "history_notes" : null,
  "history_process" : "suoxrn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "g6dv1zpvyi7",
  "history_input" : "import torch\n\nloss_fn = torch.nn.CrossEntropyLoss()",
  "history_output" : "Running",
  "history_begin_time" : 1678850764439,
  "history_end_time" : 1678850766944,
  "history_notes" : null,
  "history_process" : "ax7g0d",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "6pmffvo3ba4",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678850346167,
  "history_end_time" : 1678850346167,
  "history_notes" : null,
  "history_process" : "xdwq7e",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "9mx4lwjwq3w",
  "history_input" : "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torchmetrics\nfrom torch.utils.tensorboard.summary import hparams\n\n\ndef run_batch(\n    model,\n    loss_fn,\n    x_batch,\n    y_batch,\n    opt=None,\n    sched=None,\n    metrics=None,\n    return_pred=False,\n):\n    \"\"\"Run a batch of data through the model and return loss and metrics.\"\"\"\n    if torch.cuda.is_available():\n        loss_fn = loss_fn.to(device=\"cuda\")\n        x_batch = x_batch.to(device=\"cuda\", non_blocking=True)\n        y_batch = y_batch.to(device=\"cuda\", non_blocking=True)\n\n    # forward pass\n    logits = model(x_batch)\n    if return_pred:\n        preds = logits.argmax(axis=1).squeeze()\n    # reshape so that each pixel in seg. mask can be treated as separate instance\n    mask_flattened, logits = reshape_mask_and_predictions(y_batch, logits)\n    # compute loss\n    loss = loss_fn(logits, mask_flattened)\n    # backward pass\n    if opt is not None:\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n        if sched is not None:\n            sched.step()\n    # update metrics\n    if metrics is not None:\n        metrics.update(logits, mask_flattened)\n    if return_pred:\n        return loss.item(), preds\n    else:\n        return loss.item()\n\n\ndef reshape_mask_and_predictions(mask, prediction):\n    \"\"\"flatten mask and prediction in each batch\"\"\"\n    mask_reshaped = mask.flatten().to(torch.int64)\n    # pred_reshaped = prediction.flatten(start_dim=-2, end_dim=-1)\n    # logits shape: [B, C, 128, 128] -> [B, 128, 128, C] -> [B * 128 * 128, C]\n    pred_reshaped = prediction.permute((0, 2, 3, 1)).flatten(start_dim=0, end_dim=-2)\n    return mask_reshaped, pred_reshaped\n\n\ndef get_metrics(N, sync):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        torchmetrics.F1Score(\n            average=\"micro\",\n            dist_sync_on_step=sync,\n            num_classes=N,\n        ),\n        # torchmetrics.AUROC(dist_sync_on_step=sync, num_classes=N),\n        # StorePredLabel(dist_sync_on_step=sync),\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\n\ndef write_metrics_to_tensorboard(N, metrics, writer, epoch, train_or_val):\n    m = metrics.compute()\n    for k, v in m.items():\n        if k == \"StorePredLabel\":\n            pred, label = v\n            label = nn.functional.one_hot(label, N)\n            writer.add_pr_curve(f\"{train_or_val}/pr_curve\", label, pred, epoch)\n        # handle class-level metrics\n        elif isinstance(v, torch.Tensor) and len(v.shape) > 0 and v.shape[-1] > 1:\n            for i, v_ in enumerate(v):\n                if N == 2:  # binary\n                    l = \"negative\" if i == 0 else \"positive\"\n                elif N == 3:\n                    if i == 0:\n                        l = \"negative\"\n                    elif i == 1:\n                        l = \"anticyclonic\"\n                    elif i == 2:\n                        l = \"cyclonic\"\n                else:\n                    raise NotImplementedError(f\"{N} classes not supported\")\n                writer.add_scalar(f\"{train_or_val}/{k}_{l}\", v_, epoch)\n        else:\n            writer.add_scalar(f\"{train_or_val}/{k}\", v, epoch)\n    return m\n\n\ndef filter_scalar_metrics(metrics_dict):\n    \"\"\"Filters the output of metrics.compute() and returns only the scalar metrics.\"\"\"\n    output = {}\n    for k, v in metrics_dict.items():\n        if (isinstance(v, torch.Tensor) or isinstance(v, np.ndarray)) and len(\n            v.shape\n        ) == 0:\n            output[k] = v\n    return output\n\n\ndef add_hparams(\n    torch_tb_writer, hparam_dict, metric_dict, hparam_domain_discrete=None, epoch_num=0\n):\n    \"\"\"Add a set of hyperparameters to be compared in TensorBoard.\n    Args:\n        hparam_dict (dict): Each key-value pair in the dictionary is the\n            name of the hyper parameter and it's corresponding value.\n            The type of the value can be one of `bool`, `string`, `float`,\n            `int`, or `None`.\n        metric_dict (dict): Each key-value pair in the dictionary is the\n            name of the metric and it's corresponding value. Note that the key used\n            here should be unique in the tensorboard record. Otherwise the value\n            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n            cases, this is unwanted.\n        hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n            contains names of the hyperparameters and all discrete values they can hold\n    \"\"\"\n    torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n    if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n        raise TypeError(\"hparam_dict and metric_dict should be dictionary.\")\n    exp, ssi, sei = hparams(hparam_dict, metric_dict, hparam_domain_discrete)\n\n    torch_tb_writer.file_writer.add_summary(exp)\n    torch_tb_writer.file_writer.add_summary(ssi)\n    torch_tb_writer.file_writer.add_summary(sei)\n    for k, v in metric_dict.items():\n        torch_tb_writer.add_scalar(k, v, epoch_num)\n\n\n# Taken from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\nclass EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self,\n        patience=7,\n        verbose=False,\n        delta=0,\n        path=\"checkpoint.pt\",\n        min_epochs=30,\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            path (str): Path for the checkpoint to be saved to.\n                            Default: 'checkpoint.pt'\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.min_epochs = min_epochs\n        self.epochs = 0\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            if self.counter >= self.patience and self.epochs >= self.min_epochs:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n            self.counter = 0\n\n        self.epochs += 1\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss",
  "history_output" : "",
  "history_begin_time" : 1678850346449,
  "history_end_time" : 1678850363600,
  "history_notes" : null,
  "history_process" : "uf6vbr",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "da4zgcjg1xg",
  "history_input" : "import torchmetrics\nimport torch\nfrom create_eddy_net import *\n\ndef get_metrics(N, sync=False):\n    \"\"\"Get the metrics to be used in the training loop.\n    Args:\n        N (int): The number of classes.\n        sync (bool): Whether to use wait for metrics to sync across devices before computing value.\n    Returns:\n        train_metrics (MetricCollection): The metrics to be used in the training loop.\n        val_metrics (MetricCollection): The metrics to be used in validation.\n    \"\"\"\n    # Define metrics and move to GPU if available\n    metrics = [\n        torchmetrics.Accuracy(dist_sync_on_step=sync, num_classes=N,task=\"multiclass\"),\n        torchmetrics.Precision(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n        torchmetrics.Recall(\n            average=None,\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        ),\n#         torchmetrics.F1Score(  # TODO: Homework: verify in tensorboard that this is equivalent to accuracy\n#             average=\"micro\",\n#             dist_sync_on_step=sync,\n#             num_classes=N,\n#         ),\n        torchmetrics.F1Score(\n            average=\"none\",  # return F1 for each class\n            dist_sync_on_step=sync,\n            num_classes=N,\n          \ttask=\"multiclass\"\n        )\n    ]\n    if torch.cuda.is_available():  # move metrics to the same device as model\n        [metric.to(\"cuda\") for metric in metrics]\n\n    train_metrics = torchmetrics.MetricCollection(metrics)\n    val_metrics = train_metrics.clone()\n    return train_metrics, val_metrics\n\ntrain_metrics, val_metrics = get_metrics(num_classes)\n",
  "history_output" : "",
  "history_begin_time" : 1678850758033,
  "history_end_time" : 1678850762869,
  "history_notes" : null,
  "history_process" : "cxz2e7",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "5lilubmeiw9",
  "history_input" : "\nimport datetime\nimport os\nfrom torch.utils.tensorboard import SummaryWriter\n\ntensorboard_dir = os.path.join(\n    os.path.dirname(os.path.dirname(os.path.abspath(os.getcwd()))),\n    \"tensorboard\",\n    # add current timestamp\n    f\"{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M')}\",\n)\nwriter = SummaryWriter(log_dir=tensorboard_dir)\nprint(\n    f\"{''.join(['=']*(28 + len(writer.log_dir)))}\\\\n\"\n    f\"Writing Tensorboard logs to {writer.log_dir}\"\n    f\"\\\\n{''.join(['=']*(28 + len(writer.log_dir)))}\"\n)\n",
  "history_output" : "======================================================================\nWriting Tensorboard logs to /home/chetana/tensorboard/2023-03-15_03-26\n======================================================================\n",
  "history_begin_time" : 1678850764867,
  "history_end_time" : 1678850768893,
  "history_notes" : null,
  "history_process" : "t0vkxi",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "ezwirlljpcv",
  "history_input" : "from model_training_utils import add_hparams, EarlyStopping\nfrom get_device_config import *\nfrom loss_function import *\nfrom set_optmizer_and_scheduler import *\nfrom set_summary_writer import *\nfrom model_utils import *\nfrom torch_metrics_utils import *\nfrom tqdm.auto import tqdm\n\n\n# create some aliases\nloss, opt, sched = loss_fn, optimizer, scheduler\n\ncheckpoint_path = os.path.join(tensorboard_dir, \"model_ckpt_{epoch}.pt\")\nearly_stopping = EarlyStopping(\n    patience=10,\n    path=checkpoint_path,\n    min_epochs=30,\n)\n\nprogress_bar = tqdm(range(num_epochs), desc=\"Training: \", unit=\"epoch(s)\")\nfor N in progress_bar:\n    train_loss, val_loss, train_m, val_m = run_epoch(\n        N,\n        model,\n        loss,\n        opt,\n        sched,\n        train_loader,\n        val_loader,\n        train_metrics,\n        val_metrics,\n        writer,\n    )\n\n    # update progress bar\n    train_m_copy = {f\"train_{k}\".lower(): v.cpu().numpy() for k, v in train_m.items()}\n    val_m_copy = {f\"val_{k}\".lower(): v.cpu().numpy() for k, v in val_m.items()}\n    progress_bar.set_postfix(**train_m_copy, **val_m_copy)\n\n    # early stopping when validation loss stops improving\n    early_stopping.path = checkpoint_path.format(epoch=N)\n    early_stopping(val_loss, model)\n    if early_stopping.early_stop:\n        print(\n            f\"Early stopping at epoch {N}\"\n            f\" with validation loss {val_loss:.3f}\"\n            f\" and training loss {train_loss:.3f}\"\n        )\n        break\n\n    # TODO (homework): save checkpoint every 10 epochs\n\n# add hyperparameters and corresponding results to tensorboard HParams table\nhparam_dict = {\n    \"backbone\": model_name,\n    \"num_epochs\": num_epochs,\n    \"batch_size\": batch_size,\n    \"num_classes\": num_classes,\n    \"binary_mask\": binary,\n    \"optimizer\": optimizer.__class__.__name__,\n    \"max_lr\": max_lr,\n    \"loss_function\": loss_fn.__class__.__name__,\n}\nprint(train_m)\nmetrics_dict = {\n    \"train/end_epoch\": N,\n    \"train/loss\": train_loss,\n    \"train/Accuracy\": train_m[\"MulticlassAccuracy\"],\n    \"val/loss\": val_loss,\n    \"val/Accuracy\": val_m[\"MulticlassAccuracy\"],\n}\nadd_hparams(writer, hparam_dict, metrics_dict, epoch_num=N)\nwriter.close()\n\n# save model to tensorboard folder\nmodel_path = os.path.join(tensorboard_dir, f\"model_ckpt_{N+1}.pt\")\nprint(model_path)\ntorch.save(model.state_dict(), model_path)",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n======================================================================\nWriting Tensorboard logs to /home/chetana/tensorboard/2023-03-15_03-26\n======================================================================\n\nTraining:   0%|                                   | 0/250 [00:00<?, ?epoch(s)/s]\nTraining:   0%| | 0/250 [00:06<?, ?epoch(s)/s, train_multiclassaccuracy=0.23686,\nTraining:   0%| | 1/250 [00:06<28:00,  6.75s/epoch(s), train_multiclassaccuracy=\nTraining:   0%| | 1/250 [00:12<28:00,  6.75s/epoch(s), train_multiclassaccuracy=\nTraining:   1%| | 2/250 [00:12<24:18,  5.88s/epoch(s), train_multiclassaccuracy=\nTraining:   1%| | 2/250 [00:17<24:18,  5.88s/epoch(s), train_multiclassaccuracy=\nTraining:   1%| | 3/250 [00:17<23:42,  5.76s/epoch(s), train_multiclassaccuracy=\nTraining:   1%| | 3/250 [00:23<23:42,  5.76s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 4/250 [00:23<23:07,  5.64s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 4/250 [00:28<23:07,  5.64s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 5/250 [00:28<22:58,  5.63s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 5/250 [00:33<22:58,  5.63s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 6/250 [00:33<22:22,  5.50s/epoch(s), train_multiclassaccuracy=\nTraining:   2%| | 6/250 [00:39<22:22,  5.50s/epoch(s), train_multiclassaccuracy=\nTraining:   3%| | 7/250 [00:39<22:15,  5.50s/epoch(s), train_multiclassaccuracy=\nTraining:   3%| | 7/250 [00:44<22:15,  5.50s/epoch(s), train_multiclassaccuracy=\nTraining:   3%| | 8/250 [00:44<22:05,  5.48s/epoch(s), train_multiclassaccuracy=\nTraining:   3%| | 8/250 [00:50<22:05,  5.48s/epoch(s), train_multiclassaccuracy=\nTraining:   4%| | 9/250 [00:50<21:56,  5.46s/epoch(s), train_multiclassaccuracy=\nTraining:   4%| | 9/250 [00:55<21:56,  5.46s/epoch(s), train_multiclassaccuracy=\nTraining:   4%| | 10/250 [00:55<21:44,  5.43s/epoch(s), train_multiclassaccuracy\nTraining:   4%| | 10/250 [01:00<21:44,  5.43s/epoch(s), train_multiclassaccuracy\nTraining:   4%| | 11/250 [01:00<21:25,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   4%| | 11/250 [01:06<21:25,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   5%| | 12/250 [01:06<21:30,  5.42s/epoch(s), train_multiclassaccuracy\nTraining:   5%| | 12/250 [01:11<21:30,  5.42s/epoch(s), train_multiclassaccuracy\nTraining:   5%| | 13/250 [01:11<21:10,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:   5%| | 13/250 [01:17<21:10,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 14/250 [01:17<21:09,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 14/250 [01:22<21:09,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 15/250 [01:22<20:54,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 15/250 [01:27<20:54,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 16/250 [01:27<20:59,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   6%| | 16/250 [01:33<20:59,  5.38s/epoch(s), train_multiclassaccuracy\nTraining:   7%| | 17/250 [01:33<20:41,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:   7%| | 17/250 [01:38<20:41,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:   7%| | 18/250 [01:38<20:46,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   7%| | 18/250 [01:43<20:46,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 19/250 [01:43<20:30,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 19/250 [01:49<20:30,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 20/250 [01:49<20:34,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 20/250 [01:54<20:34,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 21/250 [01:54<20:38,  5.41s/epoch(s), train_multiclassaccuracy\nTraining:   8%| | 21/250 [01:59<20:38,  5.41s/epoch(s), train_multiclassaccuracy\nTraining:   9%| | 22/250 [01:59<20:25,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   9%| | 22/250 [02:05<20:25,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:   9%| | 23/250 [02:05<20:28,  5.41s/epoch(s), train_multiclassaccuracy\nTraining:   9%| | 23/250 [02:10<20:28,  5.41s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 24/250 [02:10<20:06,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 24/250 [02:16<20:06,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 25/250 [02:16<20:03,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 25/250 [02:21<20:03,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 26/250 [02:21<19:47,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  10%| | 26/250 [02:26<19:47,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  11%| | 27/250 [02:26<19:55,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  11%| | 27/250 [02:31<19:55,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  11%| | 28/250 [02:31<19:42,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  11%| | 28/250 [02:37<19:42,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 29/250 [02:37<19:43,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 29/250 [02:42<19:43,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 30/250 [02:42<19:33,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 30/250 [02:48<19:33,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 31/250 [02:48<19:36,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:  12%| | 31/250 [02:53<19:36,  5.37s/epoch(s), train_multiclassaccuracy\nTraining:  13%|▏| 32/250 [02:53<19:29,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  13%|▏| 32/250 [02:58<19:29,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  13%|▏| 33/250 [02:58<19:12,  5.31s/epoch(s), train_multiclassaccuracy\nTraining:  13%|▏| 33/250 [03:04<19:12,  5.31s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 34/250 [03:04<19:11,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 34/250 [03:09<19:11,  5.33s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 35/250 [03:09<19:00,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 35/250 [03:14<19:00,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 36/250 [03:14<19:02,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:  14%|▏| 36/250 [03:19<19:02,  5.34s/epoch(s), train_multiclassaccuracy\nTraining:  15%|▏| 37/250 [03:19<18:49,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  15%|▏| 37/250 [03:25<18:49,  5.30s/epoch(s), train_multiclassaccuracy\nTraining:  15%|▏| 38/250 [03:25<18:55,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  15%|▏| 38/250 [03:30<18:55,  5.36s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 39/250 [03:30<18:42,  5.32s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 39/250 [03:36<18:42,  5.32s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 40/250 [03:36<18:44,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 40/250 [03:41<18:44,  5.35s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 41/250 [03:41<18:31,  5.32s/epoch(s), train_multiclassaccuracy\nTraining:  16%|▏| 41/250 [03:47<18:31,  5.32s/epoch(s), train_multiclassaccuracy\nTraining:  17%|▏| 42/250 [03:47<19:31,  5.63s/epoch(s), train_multiclassaccuracy\nTraining:  17%|▏| 42/250 [04:00<19:31,  5.63s/epoch(s), train_multiclassaccuracy\nTraining:  17%|▏| 43/250 [04:00<27:14,  7.90s/epoch(s), train_multiclassaccuracy\nTraining:  17%|▏| 43/250 [04:11<27:14,  7.90s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 44/250 [04:11<30:25,  8.86s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 44/250 [04:21<30:25,  8.86s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 45/250 [04:21<31:27,  9.21s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 45/250 [04:35<31:27,  9.21s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 46/250 [04:35<35:27, 10.43s/epoch(s), train_multiclassaccuracy\nTraining:  18%|▏| 46/250 [04:47<35:27, 10.43s/epoch(s), train_multiclassaccuracy\nTraining:  19%|▏| 47/250 [04:47<37:11, 10.99s/epoch(s), train_multiclassaccuracy\nTraining:  19%|▏| 47/250 [05:03<37:11, 10.99s/epoch(s), train_multiclassaccuracy\nTraining:  19%|▏| 48/250 [05:04<42:30, 12.63s/epoch(s), train_multiclassaccuracy\nTraining:  19%|▏| 48/250 [05:17<42:30, 12.63s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 49/250 [05:17<42:45, 12.77s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 49/250 [05:29<42:45, 12.77s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 50/250 [05:29<42:23, 12.72s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 50/250 [05:42<42:23, 12.72s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 51/250 [05:42<42:07, 12.70s/epoch(s), train_multiclassaccuracy\nTraining:  20%|▏| 51/250 [05:52<42:07, 12.70s/epoch(s), train_multiclassaccuracy\nTraining:  21%|▏| 52/250 [05:52<39:43, 12.04s/epoch(s), train_multiclassaccuracy\nTraining:  21%|▏| 52/250 [05:58<39:43, 12.04s/epoch(s), train_multiclassaccuracy\nTraining:  21%|▏| 53/250 [05:58<33:06, 10.08s/epoch(s), train_multiclassaccuracy\nTraining:  21%|▏| 53/250 [06:03<33:06, 10.08s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 54/250 [06:03<28:28,  8.72s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 54/250 [06:09<28:28,  8.72s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 55/250 [06:09<25:22,  7.81s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 55/250 [06:14<25:22,  7.81s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 56/250 [06:14<22:54,  7.09s/epoch(s), train_multiclassaccuracy\nTraining:  22%|▏| 56/250 [06:20<22:54,  7.09s/epoch(s), train_multiclassaccuracy\nTraining:  23%|▏| 57/250 [06:20<21:22,  6.64s/epoch(s), train_multiclassaccuracy\nTraining:  23%|▏| 57/250 [06:26<21:22,  6.64s/epoch(s), train_multiclassaccuracy\nTraining:  23%|▏| 58/250 [06:26<20:07,  6.29s/epoch(s), train_multiclassaccuracy\nTraining:  23%|▏| 58/250 [06:31<20:07,  6.29s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 59/250 [06:31<19:24,  6.10s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 59/250 [06:37<19:24,  6.10s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 60/250 [06:37<18:37,  5.88s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 60/250 [06:42<18:37,  5.88s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 61/250 [06:42<18:26,  5.86s/epoch(s), train_multiclassaccuracy\nTraining:  24%|▏| 61/250 [06:48<18:26,  5.86s/epoch(s), train_multiclassaccuracy\nTraining:  25%|▏| 62/250 [06:48<18:01,  5.75s/epoch(s), train_multiclassaccuracy\nTraining:  25%|▏| 62/250 [06:54<18:01,  5.75s/epoch(s), train_multiclassaccuracy\nTraining:  25%|▎| 63/250 [06:54<17:54,  5.74s/epoch(s), train_multiclassaccuracy\nTraining:  25%|▎| 63/250 [06:59<17:54,  5.74s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 64/250 [06:59<17:34,  5.67s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 64/250 [07:05<17:34,  5.67s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 65/250 [07:05<17:27,  5.66s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 65/250 [07:10<17:27,  5.66s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 66/250 [07:10<17:06,  5.58s/epoch(s), train_multiclassaccuracy\nTraining:  26%|▎| 66/250 [07:16<17:06,  5.58s/epoch(s), train_multiclassaccuracy\nTraining:  27%|▎| 67/250 [07:16<16:59,  5.57s/epoch(s), train_multiclassaccuracy\nTraining:  27%|▎| 67/250 [07:21<16:59,  5.57s/epoch(s), train_multiclassaccuracyEarly stopping at epoch 67 with validation loss 0.000 and training loss 1.010\n\nTraining:  27%|▎| 67/250 [07:21<20:06,  6.59s/epoch(s), train_multiclassaccuracy\n{'MulticlassAccuracy': tensor(0.6411)}\n/home/chetana/tensorboard/2023-03-15_03-26/model_ckpt_68.pt\n",
  "history_begin_time" : 1678850774929,
  "history_end_time" : 1678851222622,
  "history_notes" : null,
  "history_process" : "2x5xrm",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "ot9te5mbghj",
  "history_input" : "\nimport cv2  # use cv2 to count eddies by drawing contours around segmentation masks\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom get_device_config import *\nfrom tqdm.auto import tqdm\nfrom model_training_utils import run_batch, write_metrics_to_tensorboard, filter_scalar_metrics, EarlyStopping\nfrom create_eddy_net import *\n\nnum_plots_in_tensorboard = 5\n# will populate this later with random numbers:\nrandom_plot_indices = np.zeros((num_plots_in_tensorboard,), np.uint8)\n\n\ndef run_epoch(\n    epoch,\n    model,\n    loss_fn,\n    optimizer,\n    scheduler,\n    train_loader,\n    val_loader,\n    train_metrics,\n    val_metrics,\n    writer,\n):\n    leave = epoch == num_epochs - 1  # leave progress bar on screen after last epoch\n\n    model.train()\n    # training set\n    for batch_num, (gvs, seg_masks, date_indices) in enumerate(train_loader):\n        train_loss = run_batch(\n            model, loss_fn, gvs, seg_masks, optimizer, scheduler, train_metrics\n        )\n        iter_num = epoch * len(train_loader) + batch_num\n        writer.add_scalar(\"train/lr\", scheduler.get_last_lr()[-1], iter_num)\n\n    # validation set\n    images, preds, labels, dates = [], [], [], []\n    model.eval()\n    with torch.no_grad():\n        val_loss = num_examples = 0\n        for gvs, masks, date_indices in val_loader:\n            # continue\n            loss_, pred_batch = run_batch(\n                model, loss_fn, gvs, masks, metrics=val_metrics, return_pred=True\n            )\n            val_loss += loss_\n            num_examples += np.prod(gvs.shape)\n            # keep track of images, preds, labels for plotting\n            images.append(gvs)\n            preds.append(pred_batch)\n            labels.append(masks)\n            dates.append(date_indices)\n\n    # calculate average validation loss across all samples\n    # num_examples should be equal to sum of all pixels\n    val_loss = val_loss / num_examples\n\n    # plot validation images and log to tensorboard\n    ## move images, preds, labels, dates to cpu\n    images = torch.cat(images).cpu().numpy()\n    labels = torch.cat(labels).cpu().numpy()\n    preds = torch.cat(preds).cpu().numpy()\n    dates = torch.cat(dates).cpu().numpy()\n    ## convert indices to actual dates\n    dates = [val_loader.dataset.dates[i].strftime(\"%Y-%m-%d\") for i in dates]\n\n    # take random images from validation set\n    if epoch == 0:\n        indices_ = np.random.choice(\n            len(images), num_plots_in_tensorboard, replace=False\n        )\n        for i, idx in enumerate(indices_):\n            random_plot_indices[i] = idx\n    fig, ax = plt.subplots(num_plots_in_tensorboard, 3, figsize=(20, 30))\n    for n, i in enumerate(random_plot_indices):\n        date, img, mask, pred = dates[i], images[i], labels[i], preds[i]\n        artists = plot_eddies_on_axes(\n            date, img, mask, pred, ax[n, 0], ax[n, 1], ax[n, 2]\n        )\n    plt.tight_layout()\n    writer.add_figure(f\"val/sample_prediction\", fig, global_step=epoch)\n\n    # Update tensorboard\n    train_m = write_metrics_to_tensorboard(\n        num_classes, train_metrics, writer, epoch, \"train\"\n    )\n    val_m = write_metrics_to_tensorboard(num_classes, val_metrics, writer, epoch, \"val\")\n\n    writer.add_scalar(\"train/loss\", train_loss, epoch)\n    writer.add_scalar(\"val/loss\", val_loss, epoch)\n\n    # reset metrics after each epoch\n    train_metrics.reset()\n    val_metrics.reset()\n\n    train_m = filter_scalar_metrics(train_m)\n    val_m = filter_scalar_metrics(val_m)\n\n    return train_loss, val_loss, train_m, val_m\n\n\ndef plot_eddies_on_axes(date, img, mask, pred, a1, a2, a3):\n    im1 = a1.imshow(img.squeeze(), cmap=\"viridis\")\n\n    # blit canvas for a1 a2 a3\n    a1.figure.canvas.draw()\n    a1.figure.canvas.flush_events()\n    a2.figure.canvas.draw()\n    a2.figure.canvas.flush_events()\n    a3.figure.canvas.draw()\n    a3.figure.canvas.flush_events()\n\n    # https://stackoverflow.com/a/49159236\n    t1 = a1.text(\n        0.5,\n        1.05,\n        f\"ADT {date}\",\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a1.transAxes,\n    )\n    # set axis off\n    a1.axis(\"off\")\n\n    # count number of eddies in mask and pred\n    mask_anticyclonic = count_eddies(mask, \"anticyclonic\")\n    mask_cyclonic = count_eddies(mask, \"cyclonic\")\n    pred_anticyclonic = count_eddies(pred, \"anticyclonic\")\n    pred_cyclonic = count_eddies(pred, \"cyclonic\")\n\n    # calculate accuracy between pred and mask\n    acc = np.sum(pred == mask) / mask.size\n    im2 = a2.imshow(pred, cmap=\"viridis\")\n    t2 = a2.text(\n        0.5,\n        1.05,\n        (\n            f\"Prediction (Acc = {acc:.3f} |\"\n            f\" Num. anticyclonic = {pred_anticyclonic} |\"\n            f\" Num. cyclonic = {pred_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a2.transAxes,\n    )\n    a2.axis(\"off\")\n    im3 = a3.imshow(mask, cmap=\"viridis\")\n    t3 = a3.text(\n        0.5,\n        1.05,\n        (\n            f\"Ground Truth\"\n            f\" (Num. anticyclonic: {mask_anticyclonic} |\"\n            f\" Num. cyclonic: {mask_cyclonic})\"\n        ),\n        size=plt.rcParams[\"axes.titlesize\"],\n        ha=\"center\",\n        transform=a3.transAxes,\n    )\n    a3.axis(\"off\")\n\n    return im1, t1, im2, t2, im3, t3\n\n\ndef count_eddies(arr, eddy_type=\"both\"):\n    mask = np.zeros(arr.shape, dtype=np.uint8)\n    if eddy_type == \"anticyclonic\":\n        mask[arr == 1] = 1\n    elif eddy_type == \"cyclonic\":\n        mask[arr == 2] = 1\n    else:\n        mask[arr > 0] = 1\n    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n    return len(contours)",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n",
  "history_begin_time" : 1678850768910,
  "history_end_time" : 1678850774780,
  "history_notes" : null,
  "history_process" : "3z0gs7",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "i9hdeoibryl",
  "history_input" : "from matplotlib.animation import ArtistAnimation\nfrom model_utils import *\nfrom set_summary_writer import *\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = torch.load(\"/home/chetana/tensorboard/2023-03-07_18-13/model_ckpt_3.pt\")\nmodel.eval()\nwith torch.no_grad():\n    fig, ax = plt.subplots(1, 3, figsize=(25, 10))\n    artists = []\n    # loop through all SSH maps and eddy masks in 2019\n    # and run the model to generate predicted eddy masks\n    for n, (ssh_vars, seg_masks, date_indices) in enumerate(val_loader):\n        ssh_vars = ssh_vars.to(device)\n        seg_masks = seg_masks.to(device)\n        # Run the model to generate predictions\n        preds = model(ssh_vars)\n\n        # For each pixel, EddyNet outputs predictions in probabilities,\n        # so choose the channels (0, 1, or 2) with the highest prob.\n        preds = preds.argmax(dim=1)\n\n        # Loop through all SSH maps, eddy masks, and predicted masks\n        # in this minibatch and generate a video\n        preds = preds.cpu().numpy()\n        seg_masks = seg_masks.cpu().numpy()\n        ssh_vars = ssh_vars.cpu().numpy()\n        date_indices = date_indices.cpu().numpy()\n        for i in range(len(ssh_vars)):\n            date, img, mask, pred = date_indices[i], ssh_vars[i], seg_masks[i], preds[i]\n            img1, title1, img2, title2, img3, title3 = plot_eddies_on_axes(\n                date, img, mask, pred, ax[0], ax[1], ax[2]\n            )\n            artists.append([img1, title1, img2, title2, img3, title3])\n            fig.canvas.draw()\n            fig.canvas.flush_events()\n    animation = ArtistAnimation(fig, artists, interval=200, blit=True)\n    plt.close()\n\nprint(os.path.join(tensorboard_dir, \"val_predictions.gif\"))\nanimation.save(os.path.join(tensorboard_dir, \"val_predictions.gif\"), writer=\"pillow\")\n# HTML(animation.to_jshtml())",
  "history_output" : "Read 21 samples from /home/chetana/ML_eddies/cds_ssh_1998-2018_10day_interval/subset_pet_masks_with_adt_1998-2018_lat14N-46N_lon166W-134W.npz.\nRead 12 samples from /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/subset_pet_masks_with_adt_2019_lat14N-46N_lon166W-134W.npz.\n======================================================================\nWriting Tensorboard logs to /home/chetana/tensorboard/2023-03-15_03-33\n======================================================================\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/i9hdeoibryl/eval_on_validation_set.py\", line 6, in <module>\n    model = torch.load(\"/home/chetana/tensorboard/2023-03-07_18-13/model_ckpt_3.pt\")\n  File \"/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/torch/serialization.py\", line 771, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/torch/serialization.py\", line 270, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/torch/serialization.py\", line 251, in __init__\n    super(_open_file, self).__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: '/home/chetana/tensorboard/2023-03-07_18-13/model_ckpt_3.pt'\n",
  "history_begin_time" : 1678851223527,
  "history_end_time" : 1678851229478,
  "history_notes" : null,
  "history_process" : "tcr60i",
  "host_id" : "ycru82",
  "indicator" : "Failed"
}]
