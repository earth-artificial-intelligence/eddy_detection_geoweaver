[{
  "history_id" : "paaqzlmhotz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250309051,
  "history_end_time" : 1678250309051,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "4zylrdprmrq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250309050,
  "history_end_time" : 1678250309050,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "bnj1k4sxh5y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250165309,
  "history_end_time" : 1678250276582,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "xqjkfg7idbc",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250165309,
  "history_end_time" : 1678250276582,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "2usj522ak8c",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250120270,
  "history_end_time" : 1678250120270,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "n6rq6u1l0jq",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678250120270,
  "history_end_time" : 1678250120270,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "ebn6qj3zp24",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1678213381705,
  "history_end_time" : 1678249820017,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "ii7x5nv1n5i",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678213366137,
  "history_end_time" : 1678249820017,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "q3f0cev90et",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678128154739,
  "history_end_time" : 1678128154739,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "dchvdho3d3u",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678128154739,
  "history_end_time" : 1678128154739,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "b5yzrdba2ut",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678127800432,
  "history_end_time" : 1678127800432,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "s4ziru4i47b",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678127800431,
  "history_end_time" : 1678127800431,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "87o8nfka1o6",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678127389132,
  "history_end_time" : 1678127389132,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "5iiuzwofg1x",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678127389132,
  "history_end_time" : 1678127389132,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "saudp18kqag",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678125719428,
  "history_end_time" : 1678125719428,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "5j6qx0coj3e",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1678125719428,
  "history_end_time" : 1678125719428,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "o8a0ey079ub",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1677776129139,
  "history_end_time" : 1677776132254,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "hrqyweyy5ak",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1677776103815,
  "history_end_time" : 1677776103815,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Skipped"
},{
  "history_id" : "l7zw4jc1qnd",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1677775037476,
  "history_end_time" : 1677775040401,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "qsof5viwjmi",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1677774972144,
  "history_end_time" : 1677774998324,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "dw48egoibr8",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1677174674067,
  "history_end_time" : 1677174678145,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "jljn6td0ilm",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1677174647719,
  "history_end_time" : 1677174652206,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "btqg9tdn13q",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1677174118196,
  "history_end_time" : 1677174121033,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "5uhbmmup1zs",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1677171146298,
  "history_end_time" : 1677171162466,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "tnejkcz8c2t",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676996985725,
  "history_end_time" : 1676997349610,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "0nl70gsma9o",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676996428417,
  "history_end_time" : 1676996898629,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "mhlzlprxmx0",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676996297666,
  "history_end_time" : 1676996302544,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "1ruoim91c98",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676996194989,
  "history_end_time" : 1676996198236,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "sejxnwa7lru",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676996150961,
  "history_end_time" : 1676996171001,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "lg8tuxin56o",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676923908838,
  "history_end_time" : 1676923961291,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "jut0q5uctvi",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676923359929,
  "history_end_time" : 1676923410545,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "zv074rkeu2n",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "\u001B[0m\n",
  "history_begin_time" : 1676923323915,
  "history_end_time" : 1676923345996,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "os601s3wft7",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676923256677,
  "history_end_time" : 1676923345998,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "54gbd3c45zv",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676678761132,
  "history_end_time" : 1676678764066,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "sve36ngor5k",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676678574584,
  "history_end_time" : 1676678577832,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "z8z0v1v2w29",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676678226734,
  "history_end_time" : 1676678230887,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "ylp532wv5zf",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676678177503,
  "history_end_time" : 1676678181824,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "mvymakwhevh",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676677175424,
  "history_end_time" : 1676677551322,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "qvopymls48r",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676676752581,
  "history_end_time" : 1676676756882,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "n15hyugoyd2",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676676747520,
  "history_end_time" : 1676676752685,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "rjhbujjn1qb",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676676382516,
  "history_end_time" : 1676676718053,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "13frdzr2ghs",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676676348728,
  "history_end_time" : 1676676353071,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "gkxbnsgkih3",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676676324114,
  "history_end_time" : 1676676327289,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "g94EDTcM4Msg",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676567740101,
  "history_end_time" : 1676567742939,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "6xt1a9ngwnl",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676567253283,
  "history_end_time" : 1676567256118,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "laik7sumh44",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676567234997,
  "history_end_time" : 1676567239022,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Failed"
},{
  "history_id" : "9ducllmys3a",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676565551240,
  "history_end_time" : 1676565554373,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "tdvkxjichj2",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676565544951,
  "history_end_time" : 1676565548128,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "z8grpijwbw0",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676565205835,
  "history_end_time" : 1676565445318,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "kc8jt3xviro",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676565180548,
  "history_end_time" : 1676565445318,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "92y11r72lpu",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "Running",
  "history_begin_time" : 1676565138465,
  "history_end_time" : 1676565141345,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "063qqxo6vig",
  "history_input" : "# Generate ground truth on a global scale helper functions\n\nimport multiprocessing\n\nfrom ground_truth_utils import *\n\ndef generate_masks_in_parallel(\n    files,\n    dates,\n    ssh_var=\"adt\",\n    u_var=\"ugosa\",\n    v_var=\"vgosa\",\n    high_pass_wavelength_km=700,\n    x_offset=-180,\n    y_offset=0,\n    num_processes=8,\n    plot=False,\n    save=True,\n):\n    args = [\n        (file, date, ssh_var, u_var, v_var, high_pass_wavelength_km, x_offset, y_offset)\n        for file, date in zip(files, dates)\n    ]\n    pool = multiprocessing.Pool(processes=num_processes)\n    results = pool.starmap(generate_segmentation_mask_from_file, args)\n\n    vars_ = []\n    vars_filtered = []\n    masks = []\n    for result in results:\n        vars_.append(result[0])\n        vars_filtered.append(result[1])\n        masks.append(result[2])\n\n    # concatenate list into single numpy array and return\n    masks = np.stack(masks, axis=0)\n    vars_ = np.stack(vars_, axis=0).astype(np.float32)\n    vars_filtered = np.stack(vars_filtered, axis=0).astype(np.float32)\n\n    if save:\n        # find common folder across all files\n        common_folder = os.path.commonpath(files)\n        years = sorted(set([date.year for date in dates]))\n        year_str = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n        save_path = os.path.join(\n            common_folder, f\"global_pet_masks_with_{ssh_var}_{year_str}.npz\"\n        )\n        np.savez_compressed(\n            save_path,\n            masks=masks,\n            dates=dates,\n            var=vars_,\n            var_filtered=vars_filtered,\n        )\n        print(f\"Saved masks to {save_path}\")\n\n    return vars_, vars_filtered, masks\n\n\nfrom itertools import product\n\n\ndef get_dates_and_files(years, months, days, folder, file_pattern):\n    \"\"\"\n    Given a filename pattern and a list of years months and days,\n    fill in the filename pattern with the date and return\n    a list of filenames and a list of associated `datetime` objects.\n\n    Args:\n        years (list): list of years, e.g., [1993, 1994, 1995, 1996]\n        months (list): list of months, e.g., [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n        days (list): list of days, e.g., [1, 10, 20, 30] for every 10th day\n        folder (str): folder where the files are located\n        file_pattern (str): filename pattern, e.g.,\n            \"dt_global_twosat_phy_l4_{year:04d}{month:02d}{day:02d}_vDT2021.nc\"\n\n    Returns:\n        files (list): full/absolute path to each netCDF file in the list of dates\n        dates (list): list of `datetime` objects formed from the combination of years, months and days\n    \"\"\"\n    dates, files = [], []\n    for y, m, d in product(years, months, days):  # cartesian product\n        try:\n            date = datetime(y, m, d)\n            file = os.path.join(folder, file_pattern.format(year=y, month=m, day=d))\n            dates.append(date)\n            files.append(file)\n        # catch ValueError thrown by datetime if date is not valid\n        except ValueError:\n            pass\n    years = f\"{years[0]}\" if len(years) == 1 else f\"{min(years)}-{max(years)}\"\n    print(f\"Found {len(dates)} files for {years}.\")\n    return dates, files",
  "history_output" : "",
  "history_begin_time" : 1676565113725,
  "history_end_time" : 1676565117037,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "k0c9ze8t09z",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m, fig = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "We assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nNo extrema found in contour of 4 pixels in level 0.055000\n",
  "history_begin_time" : 1676562074380,
  "history_end_time" : 1676562114501,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "k07vnmjsyxe",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m, fig = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "We assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nNo extrema found in contour of 4 pixels in level 0.055000\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/k07vnmjsyxe/generate_ground_truth_eddy.py\", line 20, in <module>\n    mask = generate_segmentation_mask(\n  File \"/home/chetana/gw-workspace/k07vnmjsyxe/ground_truth_utils.py\", line 71, in generate_segmentation_mask\n    ax, m = plot_variable(grid_dataset, mask, \"Segmentation Mask\", cmap=\"viridis\")\nValueError: too many values to unpack (expected 2)\n",
  "history_begin_time" : 1676561889043,
  "history_end_time" : 1676561927815,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Failed"
},{
  "history_id" : "z3tsu4dcps1",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m, fig = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "We assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nNo extrema found in contour of 4 pixels in level 0.055000\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/z3tsu4dcps1/generate_ground_truth_eddy.py\", line 20, in <module>\n    mask = generate_segmentation_mask(\n  File \"/home/chetana/gw-workspace/z3tsu4dcps1/ground_truth_utils.py\", line 71, in generate_segmentation_mask\n    ax, m = plot_variable(grid_dataset, mask, \"Segmentation Mask\", cmap=\"viridis\")\nValueError: too many values to unpack (expected 2)\n",
  "history_begin_time" : 1676561835349,
  "history_end_time" : 1676561875995,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Done"
},{
  "history_id" : "vifyu7lalr0",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "We assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nNo extrema found in contour of 4 pixels in level 0.055000\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/vifyu7lalr0/generate_ground_truth_eddy.py\", line 7, in <module>\n    ax, m = plot_variable(\nValueError: too many values to unpack (expected 2)\n",
  "history_begin_time" : 1676561670924,
  "history_end_time" : 1676561709855,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Failed"
},{
  "history_id" : "vq1pzv6pdvb",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "We assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\nWe assume pixel position of grid is centered for /home/chetana/ML_eddies/cds_ssh_2019_10day_interval/dt_global_twosat_phy_l4_20190110_vDT2021.nc\nNo filtering above 85.000000 degrees of latitude\n/home/chetana/anaconda3/envs/ranjan/lib/python3.10/site-packages/numpy/lib/function_base.py:4650: UserWarning: Warning: 'partition' will ignore the 'mask' of the MaskedArray.\n  arr.partition(\nNo extrema found in contour of 4 pixels in level 0.055000\nTraceback (most recent call last):\n  File \"/home/chetana/gw-workspace/vq1pzv6pdvb/generate_ground_truth_eddy.py\", line 7, in <module>\n    ax, m = plot_variable(\nValueError: too many values to unpack (expected 2)\n",
  "history_begin_time" : 1676561334654,
  "history_end_time" : 1676561374857,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Failed"
},{
  "history_id" : "ps023q7uqzn",
  "history_input" : "# Generate ground truth eddy from data\n\nfrom ground_truth_utils import *\nfrom ssh_map_preprocessing import *\n\ng, g_filtered, anticyclonic, cyclonic = identify_eddies(example_file, date)\nax, m = plot_variable(\n    g_filtered, \"adt\", \"Detected Eddies on ADT (m)\", vmin=-0.15, vmax=0.15, cmap=\"Greys\"\n)\nanticyclonic.display(\n    ax, color=\"r\", linewidth=0.75, label=\"Anticyclonic ({nb_obs} eddies)\", ref=-180\n)\ncyclonic.display(\n    ax, color=\"b\", linewidth=0.75, label=\"Cyclonic ({nb_obs} eddies)\", ref=-180\n)\nax.legend()\nupdate_axes(ax)\n\n# Plot segmentation mask\nmask = generate_segmentation_mask(\n    g_filtered, anticyclonic, cyclonic, -180, 0, plot=True\n)",
  "history_output" : "Traceback (most recent call last):\n  File \"/home/chetana/gw-workspace/ps023q7uqzn/generate_ground_truth_eddy.py\", line 3, in <module>\n    from ground_truth_utils import *\nModuleNotFoundError: No module named 'ground_truth_utils'\n",
  "history_begin_time" : 1676561259069,
  "history_end_time" : 1676561261500,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Failed"
},{
  "history_id" : "tety8szweg8",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676565494459,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "rn07davlios",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676565494459,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "9rdn12spuag",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676676718050,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "mgh6p0jypyg",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676677551321,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "f7j9kcwj16x",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676923410531,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "couglphc7oc",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676923961289,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "0px5iov0imt",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676996302542,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "bgz4h7usmd1",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676996898627,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},{
  "history_id" : "uo2ofqgjavj",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1676997349606,
  "history_notes" : null,
  "history_process" : "zhsdwn",
  "host_id" : "ycru82",
  "indicator" : "Stopped"
},]
